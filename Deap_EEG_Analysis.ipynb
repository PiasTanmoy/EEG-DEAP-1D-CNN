{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Deap EEG Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiasTanmoy/EEG-DEAP-1D-CNN/blob/main/Deap_EEG_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSeia0prWv5w",
        "outputId": "a0d70cc0-a1f1-45cc-85a3-4f06ddd9a691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "pip install git+https://github.com/forrestbao/pyeeg.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/forrestbao/pyeeg.git\n",
            "  Cloning https://github.com/forrestbao/pyeeg.git to /tmp/pip-req-build-3t4sgx7o\n",
            "  Running command git clone -q https://github.com/forrestbao/pyeeg.git /tmp/pip-req-build-3t4sgx7o\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyeeg==0.4.4) (1.18.5)\n",
            "Building wheels for collected packages: pyeeg\n",
            "  Building wheel for pyeeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyeeg: filename=pyeeg-0.4.4-py2.py3-none-any.whl size=28122 sha256=1df7efcf6d32ddd892b8e0f15bbcb41e9b2fc6bf0c2db1cf1cd3c8d4ce386f85\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t217q6q_/wheels/2d/3f/ad/106d4fc80b61d1ea1fc18e76e7439fd98aa043d83d58eae741\n",
            "Successfully built pyeeg\n",
            "Installing collected packages: pyeeg\n",
            "Successfully installed pyeeg-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WU2l9WPy2a0"
      },
      "source": [
        "#git clone https://github.com/forrestbao/pyeeg.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "358GlHIWxkMC",
        "outputId": "67e3da0f-deba-41e6-ee99-28216db986c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1R9IBrhx_Zj",
        "outputId": "f63689b7-5703-40fb-fa1c-b973c5479519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install pyeeg"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyeeg (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pyeeg\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL4hXXPVWv56"
      },
      "source": [
        "import numpy as np\n",
        "import pyeeg as pe\n",
        "import pickle as pickle\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "import os\n",
        "#import tensorflow as tf\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXqsJ3THWv6A"
      },
      "source": [
        "channel = [1,2,3,4,6,11,13,17,19,20,21,25,29,31] #14 Channels chosen to fit Emotiv Epoch+\n",
        "band = [4,8,12,16,25,45] #5 bands\n",
        "window_size = 256 #Averaging band power of 2 sec\n",
        "step_size = 16 #Each 0.125 sec update once\n",
        "sample_rate = 128 #Sampling rate of 128 Hz\n",
        "subjectList = ['01','02','03']\n",
        "#List of subjects\n",
        "path_to_dataset = '/content/drive/My Drive/Datasets/DEAP-dataset/data_preprocessed_python/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y05QKdT-Wv6H"
      },
      "source": [
        "def FFT_Processing (sub, channel, band, window_size, step_size, sample_rate):\n",
        "    '''\n",
        "    arguments:  string subject\n",
        "                list channel indice\n",
        "                list band\n",
        "                int window size for FFT\n",
        "                int step size for FFT\n",
        "                int sample rate for FFT\n",
        "    return:     void\n",
        "    '''\n",
        "    meta = []\n",
        "    with open(path_to_dataset+'s' + sub + '.dat', 'rb') as file:\n",
        "\n",
        "        subject = pickle.load(file, encoding='latin1') #resolve the python 2 data problem by encoding : latin1\n",
        "\n",
        "        for i in range (0,40):\n",
        "            # loop over 0-39 trails\n",
        "            data = subject[\"data\"][i]\n",
        "            labels = subject[\"labels\"][i]\n",
        "            start = 0;\n",
        "\n",
        "            while start + window_size < data.shape[1]:\n",
        "                meta_array = []\n",
        "                meta_data = [] #meta vector for analysis\n",
        "                for j in channel:\n",
        "                    X = data[j][start : start + window_size] #Slice raw data over 2 sec, at interval of 0.125 sec\n",
        "                    Y = pe.bin_power(X, band, sample_rate) #FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
        "                    meta_data = meta_data + list(Y[0])\n",
        "\n",
        "                meta_array.append(np.array(meta_data))\n",
        "                meta_array.append(labels)\n",
        "\n",
        "                meta.append(np.array(meta_array))    \n",
        "                start = start + step_size\n",
        "                \n",
        "        meta = np.array(meta)\n",
        "        #np.save('C:/Users/faizan/Downloads/data_preprocessed_python/data_preprocessed_python/s' + sub, meta, allow_pickle=True, fix_imports=True)\n",
        "        np.save(path_to_dataset+'s' + sub, meta, allow_pickle=True, fix_imports=True)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNBI6zlkWv6N"
      },
      "source": [
        "for subjects in subjectList:\n",
        "    FFT_Processing (subjects, channel, band, window_size, step_size, sample_rate)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39IxHP3MJhOn"
      },
      "source": [
        "import numpy as np\n",
        "# save np.load\n",
        "np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iGJHsgwWv6T"
      },
      "source": [
        "data_training = []\n",
        "label_training = []\n",
        "data_testing = []\n",
        "label_testing = []\n",
        "\n",
        "for subjects in subjectList:\n",
        "\n",
        "    with open(path_to_dataset + 's' + subjects + '.npy', 'rb') as file:\n",
        "        sub = np.load(file)\n",
        "        for i in range (0,sub.shape[0]):\n",
        "            if i % 8 == 0:\n",
        "                data_testing.append(sub[i][0])\n",
        "                label_testing.append(sub[i][1])\n",
        "            else:\n",
        "                data_training.append(sub[i][0])\n",
        "                label_training.append(sub[i][1])\n",
        "          "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrBMxsCCJjKc"
      },
      "source": [
        "# restore np.load for future normal usage\n",
        "np.load = np_load_old"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J59xEfJmJKle",
        "outputId": "c42ffc1d-9820-4081-c24d-ca129e470f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "np.save(path_to_dataset + 'data_training', np.array(data_training), allow_pickle=True, fix_imports=True)\n",
        "np.save(path_to_dataset + 'label_training', np.array(label_training), allow_pickle=True, fix_imports=True)\n",
        "print(\"training dataset:\", np.array(data_training).shape, np.array(label_training).shape)\n",
        "\n",
        "np.save(path_to_dataset + 'data_testing', np.array(data_testing), allow_pickle=True, fix_imports=True)\n",
        "np.save(path_to_dataset + 'label_testing', np.array(label_testing), allow_pickle=True, fix_imports=True)\n",
        "print(\"testing dataset:\", np.array(data_testing).shape, np.array(label_testing).shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training dataset: (51240, 70) (51240, 4)\n",
            "testing dataset: (7320, 70) (7320, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ddoeQWVWv6Z"
      },
      "source": [
        "with open(path_to_dataset + 'data_training.npy', 'rb') as fileTrain:\n",
        "    X  = np.load(fileTrain)\n",
        "    \n",
        "with open(path_to_dataset + 'label_training.npy', 'rb') as fileTrainL:\n",
        "    Y  = np.load(fileTrainL)\n",
        "    \n",
        "X = normalize(X)\n",
        "Z = np.ravel(Y[:, [1]])\n",
        "\n",
        "Arousal_Train = np.ravel(Y[:, [0]])\n",
        "Valence_Train = np.ravel(Y[:, [1]])\n",
        "Domain_Train = np.ravel(Y[:, [2]])\n",
        "Like_Train = np.ravel(Y[:, [3]])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSJHo8ZTWv6i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2Zyk_U0Wv6o"
      },
      "source": [
        "import pandas as pd\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.utils import to_categorical \n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import timeit\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Convolution1D, MaxPooling1D, ZeroPadding1D\n",
        "from keras.optimizers import SGD\n",
        "#import cv2, numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG-WXQ45Wv6t",
        "outputId": "bd4eb4bd-b88b-4506-e579-79570691c68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(Z)\n",
        "y_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkSCoKECWv6z"
      },
      "source": [
        "x_train = np.array(X[:])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkxf-DOvWv65"
      },
      "source": [
        "with open(path_to_dataset + 'data_testing.npy', 'rb') as fileTrain:\n",
        "    M  = np.load(fileTrain)\n",
        "    \n",
        "with open(path_to_dataset + 'label_testing.npy', 'rb') as fileTrainL:\n",
        "    N  = np.load(fileTrainL)\n",
        "\n",
        "M = normalize(M)\n",
        "L = np.ravel(N[:, [1]])\n",
        "\n",
        "Arousal_Test = np.ravel(N[:, [0]])\n",
        "Valence_Test = np.ravel(N[:, [1]])\n",
        "Domain_Test = np.ravel(N[:, [2]])\n",
        "Like_Test = np.ravel(N[:, [3]])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTH4Ta9QWv6-"
      },
      "source": [
        "x_test = np.array(M[:])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WwrKjBEWv7E",
        "outputId": "a2865d8e-324b-4b73-8732-d73770a6dc17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_test = to_categorical(L)\n",
        "y_test"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXrmWo9SWv7K"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.fit_transform(x_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7Vi52X5Wv7Q"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1], 1)\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1], 1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ggf1pK3Wv7V",
        "outputId": "92aba29d-8d36-4a4f-9f86-4bd13623b1a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51240, 70, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK3v3jUPWv7a"
      },
      "source": [
        "batch_size = 256\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "input_shape=(x_train.shape[1], 1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSy05krXWv7i",
        "outputId": "486adc87-92da-492b-98e9-3f4e35aed6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(input_shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9uyWA4VWv7o"
      },
      "source": [
        "from keras.layers import Convolution1D, ZeroPadding1D, MaxPooling1D, BatchNormalization, Activation, Dropout, Flatten, Dense\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjtmNdT0Wv7t",
        "outputId": "e001ed00-74d3-4edb-88a8-e34f1b6caf3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "model = Sequential()\n",
        "intput_shape=(x_train.shape[1], 1)\n",
        "model.add(Conv1D(128, kernel_size=3,padding = 'same',activation='relu', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Conv1D(128,kernel_size=3,padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "#model.add(Conv1D(64,kernel_size=3,padding = 'same', activation='relu'))\n",
        "#model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 70, 128)           512       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 70, 128)           512       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 35, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 35, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 35, 128)           512       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 17, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2176)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                139328    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 192,922\n",
            "Trainable params: 192,410\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzYyJA9aWv7z"
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhmQB52HWv73",
        "outputId": "8142bd4a-d1da-4007-992c-c0eddf5d891b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 2.0355 - accuracy: 0.2337\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.7850 - accuracy: 0.3255\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 1.6624 - accuracy: 0.3755\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.5716 - accuracy: 0.4104\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.5044 - accuracy: 0.4375\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.4405 - accuracy: 0.4675\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.4038 - accuracy: 0.4798\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.3524 - accuracy: 0.5010\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.3130 - accuracy: 0.5175\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.2864 - accuracy: 0.5269\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.2459 - accuracy: 0.5445\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.2162 - accuracy: 0.5566\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.1928 - accuracy: 0.5638\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.1716 - accuracy: 0.5735\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.1528 - accuracy: 0.5801\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.1249 - accuracy: 0.5938\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.1114 - accuracy: 0.5980\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.0870 - accuracy: 0.6065\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.0772 - accuracy: 0.6097\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.0656 - accuracy: 0.6157\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 2s 7ms/step - loss: 1.0477 - accuracy: 0.6233\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.0314 - accuracy: 0.6279\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 1.0204 - accuracy: 0.6314\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.9968 - accuracy: 0.6407\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.9952 - accuracy: 0.6416\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.9885 - accuracy: 0.6438\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.9747 - accuracy: 0.6487\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.9608 - accuracy: 0.6536\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.9586 - accuracy: 0.6553\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.9377 - accuracy: 0.6636\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.9376 - accuracy: 0.6637\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.9245 - accuracy: 0.6673\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.9219 - accuracy: 0.6676\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.9177 - accuracy: 0.6691\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8996 - accuracy: 0.6744\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8921 - accuracy: 0.6768\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8884 - accuracy: 0.6793\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8831 - accuracy: 0.6806\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8707 - accuracy: 0.6854\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8661 - accuracy: 0.6885\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8605 - accuracy: 0.6901\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8612 - accuracy: 0.6893\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8601 - accuracy: 0.6890\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8479 - accuracy: 0.6943\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8366 - accuracy: 0.6982\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8371 - accuracy: 0.6998\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8291 - accuracy: 0.7008\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8374 - accuracy: 0.7005\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8231 - accuracy: 0.7040\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.8115 - accuracy: 0.7076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f11e02f5be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy7_R94ZWv8B",
        "outputId": "c7ecd4ea-9e7c-4375-b38c-f421564e9a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "229/229 [==============================] - 1s 3ms/step - loss: 0.7444 - accuracy: 0.7310\n",
            "Test loss: 0.7444190979003906\n",
            "Test accuracy: 0.731010913848877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Q1Xh0wWv8I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}